{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7044046-7272-4f9c-84fc-79a1ade5c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Building CNN Model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c95d4-3c0f-48e3-992d-5b3320576132",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412e943-464c-4a98-9242-6766f5a8ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Using new normalized, merged image data #####\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define the directory where your normalized images are stored\n",
    "image_dir = '/sfs/weka/scratch/axu5pa/DS_4002_Project_3/PH2Dataset/normalized_images'\n",
    "\n",
    "# Define a regular expression pattern to match your desired file names.\n",
    "pattern = re.compile(r'^IMD\\d{3}_merged\\.bmp$')\n",
    "\n",
    "# List all .bmp files in the directory that match the pattern\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.bmp') and pattern.match(f)]\n",
    "\n",
    "# Create a dictionary to map image names (without .bmp) to file paths\n",
    "image_dict = {os.path.splitext(f)[0]: os.path.join(image_dir, f) for f in image_files}\n",
    "\n",
    "# Print the filtered list of image files for verification\n",
    "print(f\"Filtered Image Files: {image_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad469e-c9d6-446f-bcc6-b991b00e2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Updating our data frame #####\n",
    "import pandas as pd\n",
    "\n",
    "df['Image Path'] = df['Image Path'].str.replace(r'(?<=/)(.*)(?=\\.)', r'\\1_merged', regex=True)\n",
    "print(df['Image Path'].head())\n",
    "\n",
    "# Check if there are any missing matches\n",
    "missing_images = df[df['Image Path'].isnull()]\n",
    "\n",
    "if not missing_images.empty:\n",
    "    print(\"Some images were not found:\")\n",
    "    print(missing_images)\n",
    "else:\n",
    "    print(\"All images matched successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d396e-2647-48ad-ae32-cdf7f4c2800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### What our dataframe looks like #####\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f33bf-84c0-4ce8-9b9b-e856eedb68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image Processing Libraries\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# TensorFlow and Keras for Deep Learning\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Scikit-learn for Data Preprocessing and Model Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the directory where your normalized images are stored\n",
    "image_dir = '/sfs/weka/scratch/axu5pa/DS_4002_Project_3/PH2Dataset/normalized_images'\n",
    "\n",
    "# Define a regular expression pattern to match 'IMD___' followed by exactly three digits and ending with '.bmp'\n",
    "pattern = re.compile(r'^IMD\\d{3}(_merged)?\\.bmp$')\n",
    "\n",
    "# List all .bmp files in the directory that match the pattern\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.bmp') and pattern.match(f)]\n",
    "\n",
    "# Create a dictionary to map image names (without .bmp) to file paths\n",
    "image_dict = {os.path.splitext(f)[0]: os.path.join(image_dir, f) for f in image_files}\n",
    "\n",
    "# Sort the keys in image_dict based on the numerical part of the image names\n",
    "sorted_image_dict = {k: v for k, v in sorted(image_dict.items(), key=lambda item: int(re.search(r'\\d+', item[0]).group()))}\n",
    "\n",
    "# Sort the DataFrame by the numerical part of 'Image Name'\n",
    "df['Numeric Image Name'] = df['Image Name'].str.extract(r'(\\d+)').astype(int)  # Extract digits and convert to int\n",
    "df = df.sort_values(by='Numeric Image Name')  # Sort by the extracted numeric value\n",
    "\n",
    "# Drop the temporary 'Numeric Image Name' column\n",
    "df = df.drop(columns=['Numeric Image Name'])\n",
    "\n",
    "# Map the image paths from the dictionary to the DataFrame (with '_merged' suffix)\n",
    "df['Image Path'] = df['Image Name'].apply(lambda x: image_dict.get(f'{x}_merged', None))\n",
    "\n",
    "# Check how many successful mappings we have\n",
    "successful_mappings = df[df['Image Path'].notna()]\n",
    "print(f\"\\nNumber of successful image path mappings: {successful_mappings.shape[0]}\")\n",
    "\n",
    "# Check how many rows have failed mappings (NaN or empty 'Image Path')\n",
    "failed_mappings = df[df['Image Path'].isna()]\n",
    "print(f\"\\nNumber of failed image path mappings: {failed_mappings.shape[0]}\")\n",
    "\n",
    "# Check the first few rows with missing image paths to inspect the problem\n",
    "if not failed_mappings.empty:\n",
    "    print(\"\\nRows with failed image path mappings (missing images):\")\n",
    "    print(failed_mappings[['Image Name', 'Image Path']].head())\n",
    "\n",
    "# Drop rows where 'Image Path' is NaN or invalid\n",
    "df = df[df['Image Path'].notna() & (df['Image Path'] != '')]\n",
    "\n",
    "# If there are enough rows left to split\n",
    "if df.shape[0] > 0:\n",
    "    # Encode the 'Class' labels into integers (Benign = 0, Benign* = 1, Malignant = 2)\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Encoded Class'] = label_encoder.fit_transform(df['Class'])\n",
    "\n",
    "    # Split the dataset into training and validation sets (80% training, 20% validation)\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Encoded Class'], random_state=42)\n",
    "    \n",
    "    # Define image size and batch size\n",
    "    IMG_SIZE = (224, 224)  # Example size (can adjust based on your model's requirement)\n",
    "    BATCH_SIZE = 32       # Example batch size (can adjust based on your GPU memory)\n",
    "\n",
    "    # Create ImageDataGenerators for data augmentation and normalization\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=30,  # Increase rotation range\n",
    "        zoom_range=0.3,     # Increase zoom range\n",
    "        shear_range=0.3,    # Increase shear range\n",
    "        brightness_range=[0.8, 1.2],  # Adjust brightness\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Create generators for training and validation sets\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Image Path',\n",
    "        y_col='Encoded Class',\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='raw',  # raw because we're using encoded integers for labels\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='Image Path',\n",
    "        y_col='Encoded Class',\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='raw',\n",
    "        shuffle=False\n",
    "    )\n",
    "else:\n",
    "    print(\"Not enough valid data to proceed with train-test split.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c68a22-8a83-4b8e-b9ad-88c405dabafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet-50 model without the top layers (include_top=False)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers so they are not trained during fine-tuning\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of ResNet-50 for our specific classification task\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling instead of flattening\n",
    "\n",
    "# Add a fully connected layer with 1024 units and ReLU activation\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a final output layer with softmax activation for multi-class classification (3 classes)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Create the full model by combining the base model and our custom layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Unfreeze the last few layers for fine-tuning\n",
    "for layer in base_model.layers[-50:]:  # Unfreeze last 10 layers (adjust this number as needed)\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model after unfreezing\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),  # Lower learning rate for fine-tuning\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model with Adam optimizer and categorical crossentropy loss function (since it's multi-class classification)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary to check architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ff1cf-15fc-4bc5-8906-4329dba968bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for 10 epochs (you can adjust this based on your needs)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train with more epochs and early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.n // BATCH_SIZE,\n",
    "    epochs=20,  # Increase epochs\n",
    "    callbacks=[early_stopping]  # Add early stopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb293342-ceb5-4c85-a421-d1998f284e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values over epochs\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef61f61-f615-4a80-9af4-95a212d1eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### More model evaluation ####\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a1168-3037-4d74-acc6-4308bbd3e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image Processing Libraries\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# TensorFlow and Keras for Deep Learning\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Scikit-learn for Data Preprocessing and Model Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the directory where your normalized images are stored\n",
    "image_dir = '/sfs/weka/scratch/axu5pa/DS_4002_Project_3/PH2Dataset/normalized_images'\n",
    "\n",
    "# Define a regular expression pattern to match 'IMD___' followed by exactly three digits and ending with '.bmp'\n",
    "pattern = re.compile(r'^IMD\\d{3}(_merged)?\\.bmp$')\n",
    "\n",
    "# List all .bmp files in the directory that match the pattern\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.bmp') and pattern.match(f)]\n",
    "\n",
    "# Create a dictionary to map image names (without .bmp) to file paths\n",
    "image_dict = {os.path.splitext(f)[0]: os.path.join(image_dir, f) for f in image_files}\n",
    "\n",
    "# Sort the keys in image_dict based on the numerical part of the image names\n",
    "sorted_image_dict = {k: v for k, v in sorted(image_dict.items(), key=lambda item: int(re.search(r'\\d+', item[0]).group()))}\n",
    "\n",
    "# Sort the DataFrame by the numerical part of 'Image Name'\n",
    "df['Numeric Image Name'] = df['Image Name'].str.extract(r'(\\d+)').astype(int)  # Extract digits and convert to int\n",
    "df = df.sort_values(by='Numeric Image Name')  # Sort by the extracted numeric value\n",
    "\n",
    "# Drop the temporary 'Numeric Image Name' column\n",
    "df = df.drop(columns=['Numeric Image Name'])\n",
    "\n",
    "# Map the image paths from the dictionary to the DataFrame (with '_merged' suffix)\n",
    "df['Image Path'] = df['Image Name'].apply(lambda x: image_dict.get(f'{x}_merged', None))\n",
    "\n",
    "# Check how many successful mappings we have\n",
    "successful_mappings = df[df['Image Path'].notna()]\n",
    "print(f\"\\nNumber of successful image path mappings: {successful_mappings.shape[0]}\")\n",
    "\n",
    "# Check how many rows have failed mappings (NaN or empty 'Image Path')\n",
    "failed_mappings = df[df['Image Path'].isna()]\n",
    "print(f\"\\nNumber of failed image path mappings: {failed_mappings.shape[0]}\")\n",
    "\n",
    "# Check the first few rows with missing image paths to inspect the problem\n",
    "if not failed_mappings.empty:\n",
    "    print(\"\\nRows with failed image path mappings (missing images):\")\n",
    "    print(failed_mappings[['Image Name', 'Image Path']].head())\n",
    "\n",
    "# Define image size and batch size\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Encode the 'Class' labels into integers (Benign = 0, Benign* = 1, Malignant = 2)\n",
    "label_encoder = LabelEncoder()\n",
    "df['Encoded Class'] = label_encoder.fit_transform(df['Class'])\n",
    "\n",
    "# Split the dataset into training and validation sets (80% training, 20% validation)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Encoded Class'], random_state=42)\n",
    "\n",
    "# Print sizes of training and validation sets for debugging purposes\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "\n",
    "# Create ImageDataGenerators for data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=50,\n",
    "    zoom_range=0.5,\n",
    "    shear_range=0.5,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Image Path',\n",
    "    y_col='Encoded Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Image Path',\n",
    "    y_col='Encoded Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load pre-trained ResNet-50 model without top layers (include_top=False)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base model layers initially for transfer learning\n",
    "base_model.trainable = False\n",
    "\n",
    "# Custom top layers added on top of ResNet-50 base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)  # Add Batch Normalization layer to stabilize training\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)           # Dropout layer to prevent overfitting\n",
    "\n",
    "# Change the number of output units to match the number of classes\n",
    "predictions = Dense(3, activation='softmax')(x)  # 3 classes for 'Benign', 'Benign*', 'Malignant'\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Unfreeze last few layers of ResNet-50 for fine-tuning (experiment with different numbers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile model with Adam optimizer and lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks: EarlyStopping and ReduceLROnPlateau (learning rate scheduler)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=max(1, val_generator.n // BATCH_SIZE),  # Ensure at least one step is executed during validation\n",
    "    epochs=50,  # Increase epochs for better fine-tuning\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau],\n",
    "    verbose=2  # Increase verbosity to see detailed logs during training\n",
    ")\n",
    "\n",
    "# Plot training & validation accuracy/loss over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate final model on validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ebc6a-21fa-435d-9f47-a858a31f18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = val_generator.labels\n",
    "y_pred = np.argmax(model.predict(val_generator), axis=1)\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31c7a3-f073-4985-8102-e30681b97c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Classification ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35f8881-22ef-4950-8e36-d2f912a081f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
