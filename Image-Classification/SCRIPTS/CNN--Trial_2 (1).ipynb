{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512f460-5f3f-45b4-a71d-e8b8afe12e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /sfs/weka/scratch/axu5pa/DS_4002_Project_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8aa8e-59b5-4669-9fab-cb17e2c338c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58a1b3-455f-4876-8367-8d46dbd0f5de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "# Replace 'PH2_dataset.xlsx' with your actual file path\n",
    "df = pd.read_excel('/sfs/weka/scratch/axu5pa/DS_4002_Project_3/PH2Dataset/PH2_dataset.xlsx', skiprows=12)  # Adjust 'skiprows' based on where your actual data starts\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f2690-4a00-4fc4-bbdb-d605e9966555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Use display instead of print for a cleaner output in Jupyter Notebook\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2dbe0f-8b0f-4b23-a342-0810186183ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df2a5d-5bca-4669-8628-cdec823c1b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change directory to the desired folder\n",
    "os.chdir('/sfs/weka/scratch/axu5pa/DS_4002_Project_3')\n",
    "\n",
    "# Verify if the current working directory has changed\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f16ae-f8df-49b9-ada2-47b0f8e88be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432837b5-a788-49e6-9172-4db796b6f7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Load your dataframe (assuming it's already loaded, or you can load it from a CSV)\n",
    "# df = pd.read_csv('your_dataframe.csv')  # Load your dataframe if needed\n",
    "\n",
    "# Define the directory where your .bmp images are stored\n",
    "image_dir = '/sfs/weka/scratch/axu5pa/DS_4002_Project_3/PH2Dataset/Images'\n",
    "\n",
    "# List all .bmp files in the directory\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.bmp')]\n",
    "\n",
    "# Create a dictionary to map image names (without .bmp) to file paths\n",
    "image_dict = {os.path.splitext(f)[0]: os.path.join(image_dir, f) for f in image_files}\n",
    "\n",
    "# Add a new column to the dataframe for image paths\n",
    "df['Image Path'] = df['Image Name'].map(image_dict)\n",
    "\n",
    "# Define a function to classify based on the 'X' values in the relevant columns\n",
    "def classify_lesion(row):\n",
    "    if row['Common Nevus'] == 'X':\n",
    "        return 'Benign'\n",
    "    elif row['Atypical Nevus'] == 'X':\n",
    "        return 'Benign*'\n",
    "    elif row['Melanoma'] == 'X':\n",
    "        return 'Malignant'\n",
    "    else:\n",
    "        return 'Unknown'  # If none of the columns have an 'X'\n",
    "\n",
    "# Apply the function to each row in the dataframe to create a new 'Class' column\n",
    "df['Class'] = df.apply(classify_lesion, axis=1)\n",
    "\n",
    "# Check if there are any unknown classifications\n",
    "unknown_classifications = df[df['Class'] == 'Unknown']\n",
    "if not unknown_classifications.empty:\n",
    "    print(\"Some images were not classified correctly:\")\n",
    "    print(unknown_classifications)\n",
    "else:\n",
    "    print(\"All images classified successfully.\")\n",
    "\n",
    "# Drop the 'Lesion Type' column if it exists\n",
    "if 'Lesion Type' in df.columns:\n",
    "    df = df.drop(columns=['Lesion Type'])\n",
    "\n",
    "# Check if there are any missing matches\n",
    "missing_images = df[df['Image Path'].isnull()]\n",
    "\n",
    "if not missing_images.empty:\n",
    "    print(\"Some images were not found:\")\n",
    "    print(missing_images)\n",
    "else:\n",
    "    print(\"All images matched successfully.\")\n",
    "\n",
    "# Example: Open and display an image from the dataframe using PIL\n",
    "for index, row in df.iterrows():\n",
    "    img_path = row['Image Path']\n",
    "    if img_path:  # Ensure there's a valid path\n",
    "        img = Image.open(img_path)\n",
    "        display(img)  # Display image in Jupyter Notebook (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31213400-64d5-4281-aeba-79a39294c2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Use display instead of print for a cleaner output in Jupyter Notebook\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48402a-711d-4f95-b578-d8155094f740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df already has columns 'Common Nevus', 'Atypical Nevus', and 'Melanoma'\n",
    "\n",
    "# Define a function to classify based on the 'X' values in the relevant columns\n",
    "def classify_lesion(row):\n",
    "    if row['Common Nevus'] == 'X':\n",
    "        return 'Benign'\n",
    "    elif row['Atypical Nevus'] == 'X':\n",
    "        return 'Benign*'\n",
    "    elif row['Melanoma'] == 'X':\n",
    "        return 'Malignant'\n",
    "    else:\n",
    "        return 'Unknown'  # If none of the columns have an 'X'\n",
    "\n",
    "# Apply the function to each row in the dataframe to create a new 'Class' column\n",
    "df['Class'] = df.apply(classify_lesion, axis=1)\n",
    "\n",
    "# Check if there are any unknown classifications\n",
    "unknown_classifications = df[df['Class'] == 'Unknown']\n",
    "if not unknown_classifications.empty:\n",
    "    print(\"Some images were not classified correctly:\")\n",
    "    print(unknown_classifications)\n",
    "else:\n",
    "    print(\"All images classified successfully.\")\n",
    "\n",
    "# Drop the 'Lesion Type' column if it exists\n",
    "if 'Lesion Type' in df.columns:\n",
    "    df = df.drop(columns=['Lesion Type'])\n",
    "\n",
    "# Display the first few rows of the dataframe to verify\n",
    "from IPython.display import display\n",
    "\n",
    "# Use display instead of print for a cleaner output in Jupyter Notebook\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c997d-c9b6-4610-9f77-f9b6251eb436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######## EDA Section ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5dbdec-1285-490c-a729-9912d287191e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install matplotlib seaborn pillow numpy opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f515878-1c1c-4e36-91b2-37b0e4bd2127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageStat\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Assuming df is already loaded with the 'Image Path' and 'Class' columns\n",
    "\n",
    "# For reference:\n",
    "benign_classes = ['Common Nevus']\n",
    "benign_star_classes = ['Atypical Nevus']\n",
    "malignant_classes = ['Melanoma']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed312352-03c7-4f68-8c13-d0864a4157ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Question 1: Are the classes balanced, or is there class imbalance?\n",
    "# --------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the distribution of classes ('Benign', 'Benign*', 'Malignant')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='Class', palette='Set2')\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Distribution of Benign, Benign*, and Malignant Lesions')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print class distribution for severity check (percentage)\n",
    "class_distribution = df['Class'].value_counts(normalize=True) * 100\n",
    "print(\"Class Distribution (%):\\n\", class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6fc12-751a-426c-be55-43f69bce2227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Question 2: Are the images consistent in resolution? Do they have similar aspect ratios?\n",
    "# --------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Function to get image dimensions and aspect ratio\n",
    "def get_image_dimensions(image_path):\n",
    "    # Check if the image path is valid and not NaN\n",
    "    if isinstance(image_path, str) and os.path.exists(image_path):\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            aspect_ratio = width / height\n",
    "            return width, height, aspect_ratio\n",
    "    else:\n",
    "        return None, None, None  # Return None for invalid paths\n",
    "\n",
    "# Apply function to each row in dataframe and store results in new columns\n",
    "df[['Width', 'Height', 'Aspect Ratio']] = df['Image Path'].apply(lambda x: pd.Series(get_image_dimensions(x)))\n",
    "\n",
    "# Drop rows where dimensions couldn't be calculated (i.e., where Width is None)\n",
    "df_cleaned = df.dropna(subset=['Width'])\n",
    "\n",
    "# Plot histograms of image widths, heights, and aspect ratios\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.histplot(df_cleaned['Width'], bins=20, ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Image Width Distribution')\n",
    "\n",
    "sns.histplot(df_cleaned['Height'], bins=20, ax=axes[1], color='lightgreen')\n",
    "axes[1].set_title('Image Height Distribution')\n",
    "\n",
    "sns.histplot(df_cleaned['Aspect Ratio'], bins=20, ax=axes[2], color='salmon')\n",
    "axes[2].set_title('Image Aspect Ratio Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c482f35-7074-4c98-aa0d-7e04f95a645b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the average (mean) of 'Width', 'Height', and 'Aspect Ratio'\n",
    "average_width = df_cleaned['Width'].mean()\n",
    "average_height = df_cleaned['Height'].mean()\n",
    "average_aspect_ratio = df_cleaned['Aspect Ratio'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average Width: {average_width:.2f} pixels\")\n",
    "print(f\"Average Height: {average_height:.2f} pixels\")\n",
    "print(f\"Average Aspect Ratio: {average_aspect_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef883c9-daae-4fbc-b7da-826ce13957c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Question 3: Is there a difference in color distribution across classes?\n",
    "# --------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert 'X' values in color columns to binary (1 for 'X', 0 for NaN)\n",
    "color_columns = ['White', 'Red', 'Light-Brown', 'Dark-Brown', 'Blue-Gray', 'Black']\n",
    "df[color_columns] = df[color_columns].applymap(lambda x: 1 if x == 'X' else 0)\n",
    "\n",
    "# Melt the dataframe to long format for easier plotting\n",
    "df_melted = df.melt(id_vars='Class', value_vars=color_columns, var_name='Color', value_name='Presence')\n",
    "\n",
    "# Plot the distribution of colors by class\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_melted, x='Color', y='Presence', hue='Class', ci=None, palette='Set2')\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Color Distribution Across Lesion Classes')\n",
    "plt.xlabel('Color')\n",
    "plt.ylabel('Average Presence (1 = Present, 0 = Absent)')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d8825-a82f-4239-af62-8de72f329b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Question 4: Do images differ significantly in brightness or contrast?\n",
    "# --------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageStat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to calculate brightness and contrast of an image\n",
    "def get_brightness_contrast(image_path):\n",
    "    # Check if the image path is valid and not NaN\n",
    "    if isinstance(image_path, str) and os.path.exists(image_path):\n",
    "        img = Image.open(image_path).convert('L')  # Convert to grayscale for brightness/contrast calculation\n",
    "        stat = ImageStat.Stat(img)\n",
    "        \n",
    "        # Brightness: Mean pixel value in grayscale image\n",
    "        brightness = stat.mean[0]\n",
    "        \n",
    "        # Contrast: Standard deviation of pixel values (higher std -> higher contrast)\n",
    "        contrast = stat.stddev[0]\n",
    "        \n",
    "        return brightness, contrast\n",
    "    else:\n",
    "        return None, None  # Return None for invalid paths\n",
    "\n",
    "# Apply function to each row in dataframe and store results in new columns\n",
    "df[['Brightness', 'Contrast']] = df['Image Path'].apply(lambda x: pd.Series(get_brightness_contrast(x)))\n",
    "\n",
    "# Drop rows where brightness or contrast couldn't be calculated (i.e., where Brightness is None)\n",
    "df_cleaned = df.dropna(subset=['Brightness'])\n",
    "\n",
    "# Plot histograms of brightness and contrast values across images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "sns.histplot(df_cleaned['Brightness'], bins=20, ax=axes[0], color='orange')\n",
    "axes[0].set_title('Brightness Distribution')\n",
    "\n",
    "sns.histplot(df_cleaned['Contrast'], bins=20, ax=axes[1], color='purple')\n",
    "axes[1].set_title('Contrast Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f7068-a986-4e3c-9ca4-6f742150d424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b16853-418a-4d40-9abd-210caf215daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Building CNN Model with ResNet50 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72bcb6-3f13-4524-a70f-aa3777b530cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045b52e-d2e1-4efa-bea2-659f4c364e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### Using new normalized, merged image data #####\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define the directory where your normalized images are stored\n",
    "image_dir = '/sfs/weka/scratch/axu5pa/DS_4002_Project_3/PH2Dataset/normalized_images'\n",
    "\n",
    "# Define a regular expression pattern to match your desired file names.\n",
    "pattern = re.compile(r'^IMD\\d{3}_merged\\.bmp$')\n",
    "\n",
    "# List all .bmp files in the directory that match the pattern\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.bmp') and pattern.match(f)]\n",
    "\n",
    "# Create a dictionary to map image names (without .bmp) to file paths\n",
    "image_dict = {os.path.splitext(f)[0]: os.path.join(image_dir, f) for f in image_files}\n",
    "\n",
    "# Print the filtered list of image files for verification\n",
    "print(f\"Filtered Image Files: {image_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e529ae-2ad1-4a8e-b015-72d1d4bde4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Updating our data frame #####\n",
    "import pandas as pd\n",
    "\n",
    "df['Image Path'] = df['Image Path'].str.replace(r'(?<=/)(.*)(?=\\.)', r'\\1_merged', regex=True)\n",
    "print(df['Image Path'].head())\n",
    "\n",
    "# Check if there are any missing matches\n",
    "missing_images = df[df['Image Path'].isnull()]\n",
    "\n",
    "if not missing_images.empty:\n",
    "    print(\"Some images were not found:\")\n",
    "    print(missing_images)\n",
    "else:\n",
    "    print(\"All images matched successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0607e1-004a-4afc-9794-ee04dfbc359f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### What our dataframe looks like #####\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4806c53-8fe3-4d22-93fb-f58f7e6a0595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image Processing Libraries\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# TensorFlow and Keras for Deep Learning\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Scikit-learn for Data Preprocessing and Model Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight  # Import class_weight for computing weights\n",
    "\n",
    "# Define the directory where your normalized images are stored\n",
    "image_dir = '/sfs/weka/scratch/axu5pa/DS_4002_Project_3/PH2Dataset/normalized_images'\n",
    "\n",
    "# Define a regular expression pattern to match 'IMD___' followed by exactly three digits and ending with '.bmp'\n",
    "pattern = re.compile(r'^IMD\\d{3}(_merged)?\\.bmp$')\n",
    "\n",
    "# List all .bmp files in the directory that match the pattern\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.bmp') and pattern.match(f)]\n",
    "\n",
    "# Create a dictionary to map image names (without .bmp) to file paths\n",
    "image_dict = {os.path.splitext(f)[0]: os.path.join(image_dir, f) for f in image_files}\n",
    "\n",
    "# Sort the keys in image_dict based on the numerical part of the image names\n",
    "sorted_image_dict = {k: v for k, v in sorted(image_dict.items(), key=lambda item: int(re.search(r'\\d+', item[0]).group()))}\n",
    "\n",
    "# Map the image paths from the dictionary to the DataFrame (with '_merged' suffix)\n",
    "df['Image Path'] = df['Image Name'].apply(lambda x: image_dict.get(f'{x}_merged', None))\n",
    "\n",
    "# Encode the 'Class' labels into integers (Benign = 0, Benign* = 1, Malignant = 2)\n",
    "label_encoder = LabelEncoder()\n",
    "df['Encoded Class'] = label_encoder.fit_transform(df['Class'])\n",
    "\n",
    "# Split the dataset into training and validation sets (80% training, 20% validation)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Encoded Class'], random_state=42)\n",
    "\n",
    "# Calculate class weights based on the training set\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['Encoded Class']),\n",
    "    y=train_df['Encoded Class']\n",
    ")\n",
    "\n",
    "# Convert class_weights to a dictionary\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Create ImageDataGenerators for data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=50,\n",
    "    zoom_range=0.5,\n",
    "    shear_range=0.5,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Image Path',\n",
    "    y_col='Encoded Class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='raw',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Image Path',\n",
    "    y_col='Encoded Class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='raw',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load pre-trained ResNet-50 model without top layers (include_top=False)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base model layers initially for transfer learning\n",
    "base_model.trainable = False\n",
    "\n",
    "# Custom top layers added on top of ResNet-50 base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)  # Add Batch Normalization layer to stabilize training\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)           # Dropout layer to prevent overfitting\n",
    "\n",
    "# Change the number of output units to match the number of classes\n",
    "predictions = Dense(3, activation='softmax')(x)  # 3 classes for 'Benign', 'Benign*', 'Malignant'\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Unfreeze last few layers of ResNet-50 for fine-tuning (experiment with different numbers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile model with Adam optimizer and lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks: EarlyStopping and ReduceLROnPlateau (learning rate scheduler)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7)\n",
    "\n",
    "# Train the model with class weights\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // 64,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=max(1, val_generator.n // 64),\n",
    "    epochs=50,\n",
    "    class_weight=class_weight_dict,  # Apply class weights here\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Plot training & validation accuracy/loss over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate final model on validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daaee60-2656-47a9-90f5-20a613339f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### Confusion Matrix ######\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# Get true labels from validation dataframe\n",
    "y_true = val_df['Encoded Class'].values\n",
    "\n",
    "# Get predictions from model\n",
    "y_pred = np.argmax(model.predict(val_generator), axis=-1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print explanation\n",
    "print(\"\"\"\n",
    "Confusion Matrix Explanation:\n",
    "-----------------------------\n",
    "- Rows represent the actual classes.\n",
    "- Columns represent the predicted classes.\n",
    "- Diagonal elements (top-left to bottom-right) represent correct predictions for each class.\n",
    "- Off-diagonal elements represent misclassifications:\n",
    "  - Values in row i and column j indicate how many instances of class i were incorrectly predicted as class j.\n",
    "\n",
    "For example:\n",
    "- If you see a high value in row 0, column 1, it means many instances of 'Class 0' were incorrectly classified as 'Class 1'.\n",
    "- Ideally, most of the values should be on the diagonal, indicating correct classifications.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ee3b1-9457-43cd-97bb-1c5aeadd7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image Processing Libraries\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# TensorFlow and Keras for Deep Learning\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Scikit-learn for Data Preprocessing and Model Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight  # Import class_weight for computing weights\n",
    "\n",
    "# Define the directory where your normalized images are stored\n",
    "image_dir = '/sfs/weka/scratch/axu5pa/DS_4002_Project_3/PH2Dataset/normalized_images'\n",
    "\n",
    "# Define a regular expression pattern to match 'IMD___' followed by exactly three digits and ending with '.bmp'\n",
    "pattern = re.compile(r'^IMD\\d{3}(_merged)?\\.bmp$')\n",
    "\n",
    "# List all .bmp files in the directory that match the pattern\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.bmp') and pattern.match(f)]\n",
    "\n",
    "# Create a dictionary to map image names (without .bmp) to file paths\n",
    "image_dict = {os.path.splitext(f)[0]: os.path.join(image_dir, f) for f in image_files}\n",
    "\n",
    "# Sort the keys in image_dict based on the numerical part of the image names\n",
    "sorted_image_dict = {k: v for k, v in sorted(image_dict.items(), key=lambda item: int(re.search(r'\\d+', item[0]).group()))}\n",
    "\n",
    "# Map the image paths from the dictionary to the DataFrame (with '_merged' suffix)\n",
    "df['Image Path'] = df['Image Name'].apply(lambda x: image_dict.get(f'{x}_merged', None))\n",
    "\n",
    "# Encode the 'Class' labels into integers (Benign = 0, Benign* = 1, Malignant = 2)\n",
    "label_encoder = LabelEncoder()\n",
    "df['Encoded Class'] = label_encoder.fit_transform(df['Class'])\n",
    "\n",
    "# Split the dataset into training and validation sets (80% training, 20% validation)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Encoded Class'], random_state=42)\n",
    "\n",
    "# Calculate class weights based on the training set\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['Encoded Class']),\n",
    "    y=train_df['Encoded Class']\n",
    ")\n",
    "\n",
    "# Convert class_weights to a dictionary\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Create ImageDataGenerators for data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=50,\n",
    "    zoom_range=0.5,\n",
    "    shear_range=0.5,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Image Path',\n",
    "    y_col='Encoded Class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='raw',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Image Path',\n",
    "    y_col='Encoded Class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='raw',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load pre-trained ResNet-50 model without top layers (include_top=False)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base model layers initially for transfer learning\n",
    "base_model.trainable = False\n",
    "\n",
    "# Custom top layers added on top of ResNet-50 base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)  # Add Batch Normalization layer to stabilize training\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)           # Dropout layer to prevent overfitting\n",
    "\n",
    "# Change the number of output units to match the number of classes\n",
    "predictions = Dense(3, activation='softmax')(x)  # 3 classes for 'Benign', 'Benign*', 'Malignant'\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Unfreeze last few layers of ResNet-50 for fine-tuning (experiment with different numbers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile model with Adam optimizer and lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks: EarlyStopping and ReduceLROnPlateau (learning rate scheduler)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7)\n",
    "\n",
    "# Train the model with class weights\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // 64,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=max(1, val_generator.n // 64),\n",
    "    epochs=50,\n",
    "    class_weight=class_weight_dict,  # Apply class weights here\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Plot training & validation accuracy/loss over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate final model on validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4a254-860d-43aa-b871-9573f7a2004e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### Confusion Matrix ######\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# Get true labels from validation dataframe\n",
    "y_true = val_df['Encoded Class'].values\n",
    "\n",
    "# Get predictions from model\n",
    "y_pred = np.argmax(model.predict(val_generator), axis=-1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print explanation\n",
    "print(\"\"\"\n",
    "Confusion Matrix Explanation:\n",
    "-----------------------------\n",
    "- Rows represent the actual classes.\n",
    "- Columns represent the predicted classes.\n",
    "- Diagonal elements (top-left to bottom-right) represent correct predictions for each class.\n",
    "- Off-diagonal elements represent misclassifications:\n",
    "  - Values in row i and column j indicate how many instances of class i were incorrectly predicted as class j.\n",
    "\n",
    "For example:\n",
    "- If you see a high value in row 0, column 1, it means many instances of 'Class 0' were incorrectly classified as 'Class 1'.\n",
    "- Ideally, most of the values should be on the diagonal, indicating correct classifications.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd80b1b-56d9-453f-92aa-4865a7df3637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image Processing Libraries\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# TensorFlow and Keras for Deep Learning\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Scikit-learn for Data Preprocessing and Model Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the directory where your normalized images are stored\n",
    "image_dir = '/sfs/weka/scratch/axu5pa/DS_4002_Project_3/PH2Dataset/normalized_images'\n",
    "\n",
    "# Define a regular expression pattern to match 'IMD___' followed by exactly three digits and ending with '.bmp'\n",
    "pattern = re.compile(r'^IMD\\d{3}(_merged)?\\.bmp$')\n",
    "\n",
    "# List all .bmp files in the directory that match the pattern\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.bmp') and pattern.match(f)]\n",
    "\n",
    "# Create a dictionary to map image names (without .bmp) to file paths\n",
    "image_dict = {os.path.splitext(f)[0]: os.path.join(image_dir, f) for f in image_files}\n",
    "\n",
    "# Sort the keys in image_dict based on the numerical part of the image names\n",
    "sorted_image_dict = {k: v for k, v in sorted(image_dict.items(), key=lambda item: int(re.search(r'\\d+', item[0]).group()))}\n",
    "\n",
    "# Map the image paths from the dictionary to the DataFrame (with '_merged' suffix)\n",
    "df['Image Path'] = df['Image Name'].apply(lambda x: image_dict.get(f'{x}_merged', None))\n",
    "\n",
    "# Encode the 'Class' labels into integers (Benign = 0, Benign* = 1, Malignant = 2)\n",
    "label_encoder = LabelEncoder()\n",
    "df['Encoded Class'] = label_encoder.fit_transform(df['Class'])\n",
    "\n",
    "# Split the dataset into training and validation sets (80% training, 20% validation)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Encoded Class'], random_state=42)\n",
    "\n",
    "# Create ImageDataGenerators for data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=50,\n",
    "    zoom_range=0.5,\n",
    "    shear_range=0.5,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a class-specific generator using the `flow_from_dataframe` method with the balanced classes\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Image Path',\n",
    "    y_col='Encoded Class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='raw',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Image Path',\n",
    "    y_col='Encoded Class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='raw',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load pre-trained ResNet-50 model without top layers (include_top=False)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base model layers initially for transfer learning\n",
    "base_model.trainable = False\n",
    "\n",
    "# Custom top layers added on top of ResNet-50 base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)  # Add Batch Normalization layer to stabilize training\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)           # Dropout layer to prevent overfitting\n",
    "\n",
    "# Change the number of output units to match the number of classes\n",
    "predictions = Dense(3, activation='softmax')(x)  # 3 classes for 'Benign', 'Benign*', 'Malignant'\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Unfreeze last few layers of ResNet-50 for fine-tuning (experiment with different numbers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile model with Adam optimizer and lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks: EarlyStopping and ReduceLROnPlateau (learning rate scheduler)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // 64,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=max(1, val_generator.n // 64),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Plot training & validation accuracy/loss over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate final model on validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59564c67-226d-44aa-8a72-ea251c850274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### Confusion Matrix ######\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# Get true labels from validation dataframe\n",
    "y_true = val_df['Encoded Class'].values\n",
    "\n",
    "# Get predictions from model\n",
    "y_pred = np.argmax(model.predict(val_generator), axis=-1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print explanation\n",
    "print(\"\"\"\n",
    "Confusion Matrix Explanation:\n",
    "-----------------------------\n",
    "- Rows represent the actual classes.\n",
    "- Columns represent the predicted classes.\n",
    "- Diagonal elements (top-left to bottom-right) represent correct predictions for each class.\n",
    "- Off-diagonal elements represent misclassifications:\n",
    "  - Values in row i and column j indicate how many instances of class i were incorrectly predicted as class j.\n",
    "\n",
    "For example:\n",
    "- If you see a high value in row 0, column 1, it means many instances of 'Class 0' were incorrectly classified as 'Class 1'.\n",
    "- Ideally, most of the values should be on the diagonal, indicating correct classifications.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c18ec7-6700-459b-966e-e6f41523b5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.13.0",
   "language": "python",
   "name": "tensorflow-2.13.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
